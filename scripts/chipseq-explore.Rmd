---
title: "Exploration of CD4 ChIP-Seq Dataset"
subtitle: "`r paste0('For histone mark ', params$histone_mark, ' and transcriptome ', params$transcriptome)`"
author: "Ryan C. Thompson"
date: "`r gsub('\\s+', ' ', format(Sys.time(), '%B %e, %Y'))`"
output: html_notebook
params:
  basedir:
    value: "/home/ryan/Projects/CD4-csaw"
  transcriptome:
    value: "ensembl.85"
  histone_mark:
    value: "H3K4me3"
---

# Preliminary Setup

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE, retina=2, cache=TRUE, autodep=TRUE,
                      cache.extra = list(params=params),
                      fig.height=8, fig.width=8,
                      cache.path = paste0(file.path(params$basedir, "cache", "rnaseq-explore", params$dataset), .Platform$file.sep))
```

First we load the necessary libraries, along with a set of utility functions.

```{r load_packages, message=FALSE, cache=FALSE}
library(stringr)
library(magrittr)
library(openxlsx)
library(SummarizedExperiment)
library(dplyr)
library(edgeR)
library(limma)
library(csaw)
library(sva)
library(ggplot2)
library(scales)
library(GGally)
library(ggalt)
library(reshape2)
library(assertthat)
library(ggfortify)
library(broom)

library(BSgenome.Hsapiens.UCSC.hg38)

library(doParallel)
ncores <- getOption("mc.cores", default=parallel::detectCores(logical = FALSE))
registerDoParallel(cores=ncores)
library(BiocParallel)
register(DoparParam())

source(file.path(params$basedir, "scripts/utilities.R"))
```

# Data Loading and Preprocessing

First we load the consensus peaks called from the reads pooled from all samples. This consensus peak set is not biased toward or against any sample or condition, and therefore the peak significance is expected to be independent of any differential binding in that peak.

```{r load_peaks}
peakfile <- file.path(
    params$basedir, "peak_calls", "epic_hg38.analysisSet", 
    str_c(params$histone_mark, "_condition.ALL_donor.ALL"), 
    "peaks_noBL_IDR.narrowPeak")
allpeaks <- read.narrowPeak(peakfile) %>% as("GRanges")
seqinfo(allpeaks) <- seqinfo(BSgenome.Hsapiens.UCSC.hg38)[seqlevels(allpeaks)]
```

Now we'll load the ChIP-seq read count data set from RDS files containing SummarizedExperiment objects, and modify them to use the sample names as column names. We also ensure that the column order is identical between the two objects. Lastly, we filter out any windows with fewer than one count per sample. This is a very mild filtering criterion, but it eliminates around 75% of all the windows, greatly easing the subsequent computational burden of computing the *real* filtering threshold. 

```{r load_counts}
sexpfile <- file.path(params$basedir, "saved_data",
                      sprintf("csaw-window-counts-%s-150bp.RDS", params$histone_mark))
bigbin.sexpfile <- file.path(params$basedir, "saved_data",
                             sprintf("csaw-bigbin-counts-%s-10kb.RDS", params$histone_mark))
sexp <- readRDS(sexpfile)
bigbin.sexp <- readRDS(bigbin.sexpfile)
colnames(sexp) <- colData(sexp)$SampleName
colnames(bigbin.sexp) <- colData(bigbin.sexp)$SampleName
bigbin.sexp %<>% .[,colnames(sexp)]
assert_that(all(colnames(sexp) == colnames(bigbin.sexp)))
sexp %<>% .[rowSums(assay(.)) >= ncol(.),]
```

# Peak and Window Filtering

We begin by selecting only peaks  with an IDR value of 0.05 or less.
```{r initial_filter_peaks}
idr.threshold <- 0.05
genome.size <- seqlengths(seqinfo(allpeaks)) %>% as.numeric %>% sum
peaks <- allpeaks[allpeaks$qValue >= -log10(idr.threshold)]
pct.covered <- width(peaks) %>% sum %>% divide_by(genome.size) %>% multiply_by(100)
message(sprintf("Selected %i peaks at an IDR threshold of %.3g, with an average width of %.0f nucleotides and covering a total of %.3g%% of the genome", length(peaks), idr.threshold, mean(width(peaks)), pct.covered))
```

Now we need a strategy to filter out uninformative windows representing background regions of the genome where no specific binding is observed. First, we examine the overall distribution of average logCPM values, as well as the average logCPM distribution within called peaks:

```{r compute_aveLogCPM}
a <- aveLogCPM(asDGEList(sexp), prior.count = 2)
peak.overlap <- overlapsAny(sexp, peaks)
a.peaks <- a[peak.overlap]
```

```{r plot_aveLogCPM}
p <- ggplot(data.frame(logCPM=a, PeakOverlap=peak.overlap)) + 
    aes(x=logCPM, fill=PeakOverlap) +
    geom_histogram(aes(y=100*(..count..)/sum(..count..)), binwidth=0.1, boundary=0) +
    xlab("Average logCPM") + ylab("Percent of windows in bin") + 
    coord_cartesian(xlim=quantile(a, c(0, 0.999)), ylim=c(0,2))
ggprint(p)
```

From this plot, we conclude that a purely count-based filter is not desirable. Because the peaks represent only a small fraction of the genome, a majority of windows at any abundance level are outside peaks. This is because the random variation in coverage depth of the background reads is at least as large as the difference between peaks and unbound regions. Hence, we will simply select all windows that overlap called peaks after selecting a larger set of peaks using a more relaxed IDR threshold in order to maximize the probability of including peaks that are present in only one or a few conditions and are therefore more weakly represented in the all-sample consensus. The trade-off of including more false positive peaks is acceptable here, since false positive peaks are not expected to show evidence of differential binding.

```{r filter_peaks}
idr.threshold <- 0.2
peaks <- allpeaks[allpeaks$qValue >= -log10(idr.threshold)]
pct.covered <- width(peaks) %>% sum %>% divide_by(genome.size) %>% multiply_by(100)
message(sprintf("Selected %i peaks at an IDR threshold of %.3g, with an average width of %.0f nucleotides and covering a total of %.3g%% of the genome", length(peaks), idr.threshold, mean(width(peaks)), pct.covered))
```

```{r filter_windows_by_peak_overlap}
sexp %<>% subsetByOverlaps(peaks)
```

Lastly, we plot the resulting aveLogCPM distribution.

```{r replot_aveLogCPM}
a <- aveLogCPM(asDGEList(sexp), prior.count = 2)
p <- ggplot(data.frame(logCPM=a)) + 
    aes(x=logCPM) +
    geom_histogram(aes(y=100*(..count..)/sum(..count..)), binwidth=0.1, boundary=0) +
    xlab("Average logCPM") + ylab("Percent of windows in bin") + 
    coord_cartesian(xlim=quantile(a, c(0, 0.999))) +
ggprint(p)
```

We extract the sample metadata from the SummarizedExperiment. Since donor_id is a confounding factor, we tell R to use a factor coding that puts the intercept at the simple mean of all donors when incorporating it into a design matrix.

```{r extract_samplemeta}
sample.table <- colData(sexp) %>%
    as.data.frame %>% autoFactorize %>%
    mutate(days_after_activation=time_point %>% str_extract("\\d+$") %>% as.numeric(),
           time_point=factor(days_after_activation) %>% `levels<-`(sprintf("D%s", levels(.))),
           group=interaction(cell_type, time_point, sep=""))
contrasts(sample.table$donor_id) <- code_control(nlevels(sample.table$donor_id))
```

# Exploratory Analysis

Now we create a DGEList from the counts.

```{r prepare_dgelist}
## Extract gene metadata and colapse lists
all.gene.meta <- mcols(sexp) %>% as.data.frame
# Convert list columns to character vectors
all.gene.meta[] %<>% lapply(function(x) if (is.list(x)) sapply(x, str_c, collapse=",") else x)
dge <- DGEList(counts=assay(sexp, "counts"))
dge$genes <- all.gene.meta
```
Next we take care of the initial scaling normalization for sequencing depth and composition bias. We also discard any genes with all zero counts, since there is no meaningful analysis that can be done with these genes.

```{r initial_normalization}
## Remove all genes with zero counts in all samples
nonzero <- rowSums(dge$counts) > 0
dge %<>% .[nonzero,]
dge %<>% calcNormFactors
```

In addition, if there is a length assay, we also use that to derive an offset matrix that corrects for sample-specific biases detected by Salmon or Kallisto.

```{r generate_offsets}
if ("length" %in% assayNames(sexp)) {
    normMat <- assay(sexp, "length") %>% divide_by(exp(rowMeans(log(.)))) %>%
        .[nonzero,]
    normCounts <- dge$counts/normMat
    lib.offsets <- log(calcNormFactors(normCounts)) + log(colSums(normCounts))
    dge$offset <- t(t(log(normMat)) + lib.offsets)
}
```

We plot the distribution of average log2 CPM values to verify that our chosen presence threshold is appropriate. The distribution is expected to be bimodal, with a low-abundance peak representing non-expressed genes and a high-abundance peak representing expressed genes. The chosen threshold should separate the two peaks of the bimodal distribution.

```{r aveLogCPM_plots}
a <- aveLogCPM(dge)
avelogcpm.presence.threshold <- -1

p <- list(
    Histogram=ggplot(data.frame(logCPM=a)) +
        aes(x=logCPM) +
        geom_histogram(aes(y=100*(..count..)/sum(..count..)), binwidth=0.25, boundary=0) +
        geom_vline(xintercept=avelogcpm.presence.threshold, color="red", linetype="dashed") +
        xlab("Average logCPM") + ylab("Percent of genes in bin") +
        coord_cartesian(xlim=quantile(a, c(0, 0.995)), ylim=c(0,10)) +
        labs(title="Average gene LogCPM distribution",
             subtitle="for genes with at least 1 read") +
        theme(plot.caption = element_text(hjust = 0)),
    ECDF=ggplot(fortify(ecdf(a))) +
        aes(x=x, y=y*100) +
        geom_step() +
        geom_vline(xintercept=avelogcpm.presence.threshold, color="red", linetype="dashed") +
        xlab("Average logCPM") + ylab("Percent of genes with smaller average logCPM") +
        coord_cartesian(xlim=quantile(a, c(0, 0.995))) +
        labs(title="Empirical Cumulative Distribution Function of gene LogCPM values",
             subtitle="for genes with at least 1 read") +
        theme(plot.caption = element_text(hjust = 0)))

ggprint(p)
```

```{r avelogCPM_plots_pdf, cache=FALSE, include=FALSE}
ggprint(p, device=cairo_pdf(file.path(plotdir, "AveLogCPM-plots.pdf"), onefile=TRUE))
```

The red dashed line in each plot indicates the chosen presence threshold. We now subset the DGEList to only those genes above the threshold.

```{r abundance_filter_genes}
dge %<>% .[aveLogCPMWithOffset(.) >= avelogcpm.presence.threshold,]
```

Now we estimate the dispersions for each gene, to get an idea of what the variability of this data set is like. In order to evaluate the effect of empirical Bayes shrinkage on the dispersions, we estimate the gene dispersions in 3 different ways: once with no inter-gene information sharing, once with ordinary shrinkage, and once with robust shrinkage, which reduces the strength of shrinkage for outlier genes whose dispersion is farthest away from the trend.

```{r estimate_disp}
design <- model.matrix(~0 + group + donor_id, sample.table)
colnames(design) %<>% str_replace("^group", "")

dge %<>% estimateDisp(design, robust=TRUE)

message("Common dispersion: ", dge$common.dispersion)
message("BCV: ", sqrt(dge$common.dispersion))

dge.with.eBayes <- dge %>% estimateDisp(design, robust=FALSE)
dge.with.robust.eBayes <- dge %>% estimateDisp(design, robust=TRUE)
dge.without.eBayes <- dge %>% estimateDisp(design, prior.df=0)
```

We now plot all 3 dispersion estimates, along with the overall average and estimated trend. Each plot includes the points from the previous plots in lighter colors for comparison.

```{r plot_disp}
disptable <- data.frame(
    logCPM=dge.without.eBayes$AveLogCPM,
    CommonBCV=dge.with.eBayes$common.dispersion %>% sqrt,
    TrendBCV=dge.with.eBayes$trended.dispersion %>% sqrt,
    GeneWiseBCV=dge.without.eBayes$tagwise.dispersion %>% sqrt,
    eBayesBCV=dge.with.eBayes$tagwise.dispersion %>% sqrt,
    RobustBCV=dge.with.robust.eBayes$tagwise.dispersion %>% sqrt) %>%
    cbind(dge$genes)

## Reduce the number of points to plot for each line for performance
## reasons
npoints <- c(Common=2, Trend=500)
disp.line.table <-
    disptable %>%
    select(logCPM, TrendBCV, CommonBCV) %>%
    melt(id.vars="logCPM", variable.name="DispType", value.name = "BCV") %>%
    mutate(DispType=str_replace(DispType, "BCV$", "")) %>%
    group_by(DispType) %>%
    do({
        spline(x=.$logCPM, y=.$BCV, n=npoints[.$DispType[1]]) %>% data.frame(logCPM=.$x, BCV=.$y)
    })

baseplot <- ggplot(disptable) +
    aes(x=logCPM)
raw.disp.plot <- baseplot +
    geom_point(aes(y=GeneWiseBCV), size=0.1, color="black") +
    geom_line(data=disp.line.table, aes(x=logCPM, y=BCV, group=DispType), color="white", size=1.5, alpha=0.5) +
    geom_line(data=disp.line.table, aes(x=logCPM, y=BCV, linetype=DispType), color="darkred", size=0.5) +
    scale_linetype_manual(name="Dispersion Type", values=c(Trend="solid", Common="dashed")) +
    ylab("Biological coefficient of variation") +
    ggtitle("BCV plot (Raw dispersions)")

eBayes.disp.plot <- baseplot +
    geom_point(aes(y=GeneWiseBCV), size=0.4, color="gray") +
    geom_point(aes(y=eBayesBCV), size=0.1, color="darkblue") +
    geom_line(data=disp.line.table, aes(x=logCPM, y=BCV, group=DispType), color="white", size=1.5, alpha=0.5) +
    geom_line(data=disp.line.table, aes(x=logCPM, y=BCV, linetype=DispType), color="darkred", size=0.5) +
    scale_linetype_manual(name="Dispersion Type", values=c(Trend="solid", Common="dashed")) +
    ylab("Biological coefficient of variation") +
    ggtitle("BCV plot (Raw & squeezed dispersions)")

robust.eBayes.disp.plot <- baseplot +
    geom_point(aes(y=GeneWiseBCV), size=0.4, color="gray") +
    geom_point(aes(y=eBayesBCV), size=0.4, color="deepskyblue") +
    geom_point(aes(y=RobustBCV), size=0.1, color="darkgreen") +
    geom_line(data=disp.line.table, aes(x=logCPM, y=BCV, group=DispType), color="white", size=1.5, alpha=0.5) +
    geom_line(data=disp.line.table, aes(x=logCPM, y=BCV, linetype=DispType), color="darkred", size=0.5) +
    scale_linetype_manual(name="Dispersion Type", values=c(Trend="solid", Common="dashed")) +
    ylab("Biological coefficient of variation") +
    ggtitle("BCV plot (Raw & squeezed & robust dispersions)")

p <- list(raw.disp.plot, eBayes.disp.plot, robust.eBayes.disp.plot)
ggprint(p)
```

```{r plot_disp_pdf, cache=FALSE, include=FALSE}
ggprint(p, device=cairo_pdf(file.path(plotdir, "disp-plots.pdf"), onefile=TRUE))
rasterpdf(file.path(plotdir, "disp-plots.pdf"), resolution=600)
```

Next, we use limma's sample weight calculating methods to investigate possible quality issues. To confirm our results, we also split the samples into treatment groups and use edgeR to estimate the dispersion within each group. This is a crude method, and these group-specific dispersion estimate would be too unstable for use in a differential expression analysis, but comparing the overall mean dispersion for each sample to the sample quality weights determined by limma provides a useful sanity check.

```{r compute_quality_weights, message=FALSE, warning=FALSE}
elist.w <- voomWithQualityWeightsAndOffset(dge, design)
dbg <- estimateDispByGroup(dge, sample.table$group, sample.table$batch)
```

To see whether the weights are correlated with specific experimental factors, we create a boxplot of the weights and group dispersions against each relevant covariate.

```{r plot_quality_weights}
covars <- sample.table %>% dplyr::select(group, time_point, donor_id, batch, cell_type)
qcmetrics <- data.frame(Weight=elist.w$sample.weights,
                        GroupBCV=sapply(dbg, `[[`, "common.dispersion")[as.character(covars$group)])

p <- ggduo.dataXY(covars, qcmetrics %>% transmute(Log2Weight=log2(Weight), GroupBCV)) +
  ggtitle("Weights and dispersions by group") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust=0.5))
ggprint(p)
```

```{r plot_quality_weights_pdf, cache=FALSE, include=FALSE}
ggprint(p, device=cairo_pdf(file.path(plotdir, "qc-weights.pdf"), onefile = TRUE))
```
We also make plots of the individual weights against each covariate, and compute the ANOVA p-value for the relationship between the weights and each covariate separately.

(Note for later: It would be good to try all covariates in the same model as random effects.)

```{r plot_weights_vs_covars}
awdf <- data.frame(covars, qcmetrics)
anovas <- lapply(colnames(covars), function(x) {
    formula <- as.formula(str_c("log2(Weight) ~ ", x))
    lm(formula, awdf) %>% aov %>% tidy %>% filter(term == x)
}) %>%
    do.call(what=rbind) %>%
    mutate(padj=p.adjust(p.value, method="BH"))
pvals <- anovas %$% setNames(p.value, term)
aw.plot.base <- ggplot(awdf) +
    aes(y=Weight) +
    scale_y_continuous(trans=log_trans(2)) +
    geom_dotplot(binaxis = "y", stackdir="center", binwidth=0.1)
p <- lapply(colnames(covars), function(x) {
    pretty.covar.name <- x %>% str_replace_all("_", " ") %>% str_to_title
    aw.plot.base + aes_string(x=x) +
        labs(title=str_c("Array weights by ", pretty.covar.name),
             subtitle=sprintf("ANOVA p-value = %0.3g", pvals[x]))
})
ggprint(p)
```

```{r plot_weights_vs_covars_pdf, cache=FALSE, include=FALSE}
ggprint(p, device=cairo_pdf(file.path(plotdir, "weights-vs-covars.pdf"), onefile = TRUE))
```

Next we perform several methods of batch correction on the voom-transformed data. First, we try direct batch subtraction using limma's `removeBatchEffect` function, which fits a linear model with the batches as sum-to-zero coefficients and then subtracts the batch coefficients from the data.

```{r batch_subtract}
elist.bc <- elist.w
# Batch is confounded with time point, so we leave it out of the design for this step
design.NoTime <- model.matrix(~0 + cell_type + donor_id, sample.table)
elist.bc$E %<>%
    removeBatchEffect(batch=sample.table %$% batch:donor_id, design=design.NoTime,
                      weights=elist.bc$weights)
```

Second, we use ComBat, which performs empirical Bayes shrinkage of the batch correction parameters. First, we run ComBat in parametric prior mode in order to produce a diagnostic plot of the priors. Note that we use ComBat here to subtract both the batch and donor effects, so that the MDS plots will be more reflective of the desired biological effects.

```{r combat_plot}
design.cb <- model.matrix(~cell_type, sample.table)
# Right now we're just running ComBat to produce the plot, so we discard the output.
invisible(capture.output(BPComBat(elist.w$E, batch=sample.table %$% batch:donor_id, mod=design.cb, par.prior=TRUE, prior.plots = TRUE)))
```

```{r combat_plot_pdf, echo=TRUE, message=FALSE, cache=FALSE}
cairo_pdf(file.path(plotdir, "rnaseq-ComBat-qc.pdf"))
# Run the same thing again to output the plot to the PDF file
invisible(BPComBat(elist.w$E, batch=sample.table %$% batch:donor_id, mod=design.cb, par.prior=TRUE, prior.plots = TRUE))
invisible(dev.off())
```

These plots look similar to the ones in dataset 1 of the ComBat paper, for which the parametric prior was chosen. So this analysis will do likewise.

```{r combat_adjust}
# Now perform the actual batch correction using non-parametric prior
design.cb <- model.matrix(~cell_type, sample.table)
elist.cb <- elist.w
elist.cb$E %<>% BPComBat(batch=sample.table %$% batch:donor_id, mod=design.cb, par.prior=TRUE)
```

For each of the batch correction methods, we compute the sample distance matrix using multidimensional scaling and plot the first 3 principal coordinates. We reflect all the principal coordinates so as to make the mean of the Naive D0 samples negative in all dimensions, so that MDS plots will be oriented consistently between different reports. 

```{r batch_correction_mds_plot, warning=FALSE}
naive.d0.samples <- sample.table$group == "NaiveD0"
dmat <- suppressPlot(plotMDS(elist.w)$distance.matrix) %>% as.dist
mds <- cmdscale(dmat, k=attr(dmat, "Size") - 1, eig=TRUE)
mds$points %<>% scale(center=FALSE, scale=-sign(colMeans(.[naive.d0.samples,]))) %>%
    add.numbered.colnames("Dim") %>% data.frame(sample.table, .)
dmat.bc <- suppressPlot(plotMDS(elist.bc)$distance.matrix) %>% as.dist
mds.bc <- cmdscale(dmat.bc, k=attr(dmat, "Size") - 1, eig=TRUE)
mds.bc$points %<>% scale(center=FALSE, scale=sign(colMeans(.[naive.d0.samples,]))) %>%
    add.numbered.colnames("Dim") %>% data.frame(sample.table, .)
dmat.cb <- suppressPlot(plotMDS(elist.cb)$distance.matrix) %>% as.dist
mds.cb <- cmdscale(dmat.cb, k=attr(dmat, "Size") - 1, eig=TRUE)
mds.cb$points %<>% scale(center=FALSE, scale=sign(colMeans(.[naive.d0.samples,]))) %>%
     add.numbered.colnames("Dim") %>% data.frame(sample.table, .)

ggmdsbatch <- function(dat, dims=1:2) {
    if (length(dims) == 1) {
        dims <- dims + c(0,1)
    }
    assert_that(length(dims) == 2)
    ggplot(dat) +
        aes_string(x=str_c("Dim", dims[1]), y=str_c("Dim", dims[2])) +
        aes(color=batch, label=SampleName) +
        geom_text() +
        scale_x_continuous(expand=c(0.15, 0)) +
        coord_equal()
}

p <- list(
    ggmdsbatch(mds$points) +
        labs(title="limma voom Principal Coordinates 1 & 2",
             subtitle="No batch correction"),
    ggmdsbatch(mds.bc$points) +
        labs(title="limma voom Principal Coordinates 1 & 2",
             subtitle="After naive batch subtraction"),
    ggmdsbatch(mds.cb$points) +
        ggtitle("limma voom Principal Coordinates 1 & 2",
             subtitle="After ComBat batch correction"),
    ggmdsbatch(mds$points, dims=2:3) +
        ggtitle("limma voom Principal Coordinates 2 & 3",
             subtitle="No batch correction"),
    ggmdsbatch(mds.bc$points, dims=2:3) +
        ggtitle("limma voom Principal Coordinates 2 & 3",
             subtitle="After naive batch subtraction"),
    ggmdsbatch(mds.cb$points, dims=2:3) +
        ggtitle("limma voom Principal Coordinates 2 & 3",
             subtitle="After ComBat batch correction"))
ggprint(p)
```

```{r batch_correction_mds_plot_pdf, cache=FALSE, include=FALSE}
ggprint(p, device=cairo_pdf(file.path(plotdir, "rnaseq-MDSPlots-BatchCorrect.pdf"), width=12, height=12, onefile = TRUE))
```

Choosing ComBat as the best-looking batch correction, we make more MDS plots for this data, this time plotting the first 5 PCs and adding the experimental information to the plot as colors and shapes.

```{r mds_plot}
xlims <- range(unlist(mds.cb$points[c("Dim1", "Dim2")]))
ylims <- range(unlist(mds.cb$points[c("Dim2", "Dim3")]))
pbase <- ggplot(mds.cb$points) +
    aes(x=Dim1, y=Dim2, label=SampleName, color=batch, fill=time_point, shape=cell_type, linetype=donor_id, group=cell_type:donor_id) +
    geom_encircle(aes(group=time_point:cell_type, color=NULL), s_shape=0.75, expand=0.05, color=NA, alpha=0.2) +
    geom_path(color=hcl(c=0, l=45), aes(color=NULL)) +
    geom_point(size=4) +
    scale_shape_manual(values=c(Naive=21, Memory=24)) +
    scale_color_manual(values=col2hcl(c(B1="green", B2="magenta"), l=80)) +
    scale_fill_hue(l=55) +
    scale_linetype_manual(values=c("solid", "dashed", "dotdash", "twodash")) +
    guides(colour = guide_legend(override.aes = list(shape = 21)),
           fill = guide_legend(override.aes = list(shape = 21)),
           shape = guide_legend(override.aes = list(color=hcl(c=0, l=80), fill=hcl(c=0, l=55)))) +
    labs(title="limma voom Principal Coordinates 1 & 2",
         subtitle=" (after ComBat batch correction)") +
    coord_equal(xlim=xlims, ylim=ylims)
p <- list(PC12=pbase,
          PC23=pbase +
              aes(x=Dim2, y=Dim3) +
              labs(title="limma voom Principal Coordinates 2 & 3"),
          PC34=pbase +
              aes(x=Dim3, y=Dim4) +
              labs(title="limma voom Principal Coordinates 3 & 4"),
          PC45=pbase +
              aes(x=Dim4, y=Dim5) +
              labs(title="limma voom Principal Coordinates 4 & 5"))
ggprint(p)
```

```{r mds_plot_pdf, cache=FALSE, include=FALSE}
ggprint(p, device=cairo_pdf(file.path(plotdir, "rnaseq-MDSPlots.pdf"), onefile = TRUE))
```

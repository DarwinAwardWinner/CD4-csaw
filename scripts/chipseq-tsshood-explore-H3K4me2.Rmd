---
title: "Exploration of CD4 ChIP-Seq Promoter Dataset"
subtitle: '`r glue::glue_data(params, "For histone mark {histone_mark} using {transcriptome} annotation on {genome} genome")`'
author: "Ryan C. Thompson"
date: '`r stringr::str_replace_all(format(Sys.time(), "%B %e, %Y"), "[[:space:]]+", " ")`'
output:
    html_document:
        toc: true
        toc_float: true
    html_notebook:
        toc: true
        toc_float: true
params:
    genome:
        value: hg38.analysisSet
    transcriptome:
        value: ensembl.85
    histone_mark:
        value: H3K4me2
    neighborhood_radius:
        value: 5kbp
    window_size:
        value: 500bp
    fragment_length:
        value: 147bp
    bigbin_size:
        value: 10kbp
---

# Preliminary Setup

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(echo = TRUE, retina = 2, cache = TRUE, autodep = TRUE,
                      cache.extra = list(params = params),
                      # https://github.com/yihui/knitr/issues/572
                      cache.lazy = FALSE,
                      fig.height = 8, fig.width = 8,
                      cache.path = paste0(
                          here::here("cache", "chipseq-tsshood-explore", params$histone_mark),
                          .Platform$file.sep))
```

First we load the necessary libraries, along with a set of utility functions.

```{r load_packages, message = FALSE, cache = FALSE}
library(here)
library(stringr)
library(glue)
library(magrittr)
library(SummarizedExperiment)
library(dplyr)
library(tibble)
library(edgeR)
library(limma)
library(csaw)
library(sva)
library(ggplot2)
library(scales)
library(GGally)
library(ggalt)
library(plotly)
library(reshape2)
library(assertthat)
library(ks)
library(RColorBrewer)
library(variancePartition)
library(forcats)
library(broom)
library(rctutils)

library(BSgenome.Hsapiens.UCSC.hg38)

library(BiocParallel)
library(future)
options(future.globals.maxSize = 4 * 1024^3)
use_futures("multicore")
```

We also set the random seed for reproducibility:

```{r set_random_seed}
set.seed(1986)
```

# Data Loading and Preprocessing

First we load the consensus peaks called from the reads pooled from all samples. This consensus peak set is not biased toward or against any sample or condition, and therefore the peak significance is expected to be independent of any differential binding in that peak.

```{r load_peaks}
# Currently no other genome supported, but it could be.
assert_that(params$genome == "hg38.analysisSet")
peakfile <- here(
    "peak_calls", glue("epic_{params$genome}"),
    glue_data(params, "{histone_mark}_condition.ALL_donor.ALL"),
    "peaks_noBL_IDR.narrowPeak")
allpeaks <- {
    read_narrowPeak(peakfile) %>%
        assign_into(seqinfo(.), seqinfo(BSgenome.Hsapiens.UCSC.hg38)[seqlevels(.)]) %>%
        setNames(.$name)
}
```

Now we'll load the ChIP-seq read count data set from RDS files containing SummarizedExperiment objects, and modify them to use the sample names as column names. We also ensure that the column order is identical between the two objects.

```{r load_counts}
sexpfile <-
    here("saved_data",
         glue_data(params, "tss-neighborhood-counts_{genome}_{transcriptome}_{neighborhood_radius}-radius_{window_size}-windows_{fragment_length}-reads_{histone_mark}.RDS"))
bigbin_sexpfile <- here("saved_data", glue_data(params, "chipseq-counts_{bigbin_size}-bigbins_{histone_mark}.RDS"))
bigbin_sexp <- readRDS(bigbin_sexpfile)
sexp <- readRDS(sexpfile)
colnames(sexp) <- colData(sexp)$SampleName
colnames(bigbin_sexp) <- colData(bigbin_sexp)$SampleName
# Ensure identical column order
bigbin_sexp %<>% .[,colnames(sexp)]
assert_that(all(colnames(sexp) == colnames(bigbin_sexp)))
```

We extract the sample metadata from the SummarizedExperiment. We set all factors to use a sum-to-zero variant of the treatment-contrast coding, which will ease the subtraction of batch effects later.

```{r extract_samplemeta}
sample_table <- colData(sexp) %>%
    as.data.frame %>% auto_factorize_columns %>%
    mutate(days_after_activation = time_point %>% str_extract("\\d+$") %>% as.numeric(),
           group = interaction(cell_type, time_point, sep = "")) %>%
    auto_factorize_columns %>%
    set_rownames(colnames(sexp))
for (i in names(sample_table)) {
    if (is.factor(sample_table[[i]]) && nlevels(sample_table[[i]]) > 1) {
        sample_table[[i]] %<>% C(code_control_named(levels(.)))
    }
}
```

Last, we load the RNA-seq data, and fix up the strandedness if necessary.

```{r load_rnaseq}
rnaseq_sexp <- {
    readRDS(here("saved_data", glue_data(params, "SummarizedExperiment_rnaseq_shoal_hg38.analysisSet_{transcriptome}.RDS"))) %>%
    set_colnames(colData(.)$SRA_run)
}
# Fix up stranded RNA-seq counts, if needed
libtype.assayNames <- c(SF = "sense.counts", SR = "antisense.counts")
if (all(libtype.assayNames %in% assayNames(rnaseq_sexp))) {
    message("Selecting stranded counts for each sample")
    sample.table %<>% mutate(count_type = libtype.assayNames[libType])
    assay(rnaseq_sexp, "unstranded.counts") <- assay(rnaseq_sexp, "counts")
    assay(rnaseq_sexp, "counts") <- lapply(seq_len(nrow(sample.table)), function(i) {
        message("Using ", sample.table[i,]$count_type, " for ", colnames(rnaseq_sexp)[i])
        assay(rnaseq_sexp, sample.table[i,]$count_type %>% as.character)[,i]
    }) %>% do.call(what = cbind)
    total.counts <- sexp %>% assays %>% sapply(colSums) %>% data.frame %>%
        mutate(SampleName = row.names(.)) %>%
        inner_join(sample.table, by = "SampleName")
    total.counts %$% invisible(assert_that(all(counts == pmax(sense.counts, antisense.counts))))
}
```

# Computing promoter counts

We generate a SummarizedExperiment containing counts for whole promoter neighborhoods by adding up all the windows in each neighborhood. The result has one row per gene. The count for each neighborhood is simply the sum of window counts in that neighborhood, since each read was binned into exactly one window.

```{r sum_neighborhoods}
nhood_rl <- rowRanges(sexp) %>% split(.$GeneID)
nhood_ranges <- reduce(nhood_rl) %>% {assert_that(all(lengths(.) == 1)); .} %>% unlist
mcols(nhood_ranges) <- nhood_rl %>% .[rep(List(1), length(.))] %>% unlist %>% mcols
mcols(nhood_ranges)$offset <- NULL
mcols(nhood_ranges)$blacklist <- mcols(sexp) %$% split(blacklist, GeneID) %>% sapply(mean) %>% .[names(nhood_ranges)]
nhood_counts <- assay(sexp, "counts") %>% rowsum(mcols(sexp)$GeneID)
nhood_sexp <- SummarizedExperiment(
    assays = List(counts=nhood_counts),
    rowRanges=nhood_ranges,
    colData=colData(sexp),
    metadata=metadata(sexp))
```

# Filtering unbound promoters

We begin by selecting only peaks  with an IDR value of 0.05 or less, and then determine the set of promoters that overlap these peaks.

```{r filter_peaks}
idr_threshold <- 0.05
genome_size <- seqlengths(seqinfo(allpeaks)) %>% as.numeric %>% sum
# IDR is encoded in the qValue field of the narrowPeak file
peaks <- allpeaks[allpeaks$qValue >= -log10(idr_threshold)]
pct_genome_covered <- width(peaks) %>% sum %>% divide_by(genome_size) %>% multiply_by(100)
peak_overlap <- overlapsAny(nhood_sexp, peaks)
pct_promoters_covered <- mean(peak_overlap) * 100
message(glue("Selected {length(peaks)} peaks at an IDR threshold of {format(idr_threshold, digits = 3)}, with an average width of {round(mean(width(peaks)))}, covering a total of {format(pct_genome_covered, digits = 3)}%% of the genome and {format(pct_promoters_covered, digits = 3)}% of promoters."))
```

We need a strategy to filter out unbound promoters representing background regions of the genome where no specific binding is observed. First, we examine the overall distribution of average logCPM values, splitting the distribution based on which promoters overlap peaks:

```{r compute_aveLogCPM}
a <- aveLogCPM(asDGEList(nhood_sexp), prior.count = 2)
```

```{r plot_aveLogCPM}
adata <- data.frame(logCPM = a, PeakOverlap = peak_overlap)
threshold_q <- 0.01
logcpm_threshold <- adata %>% filter(PeakOverlap) %$% quantile(logCPM, threshold_q)
count_threshold <- 2^logcpm_threshold * mean(colData(sexp)$totals) / 1e6
message(glue("
    Filter theshold at {threshold_q} quantile of peak-overlapping promoters is {format(count_threshold, digits = 3)} reads, a logCPM of {format(logcpm_threshold, digits = 3)}. \\
    This threshold keeps {format(100 * mean(a >= logcpm_threshold), digits = 3)}% of promoters.
"))
p <- list(
    Histogram = ggplot(adata) +
        aes(x = logCPM, fill = PeakOverlap) +
        geom_histogram(aes(y = 100*(..count..)/sum(..count..)), binwidth = 0.1, boundary = 0) +
        geom_vline(xintercept = logcpm_threshold, linetype = "dashed") +
        xlab("Average logCPM") + ylab("Percent of promoters in bin") +
        coord_cartesian(xlim = quantile(a, c(0, 0.999)), ylim = c(0,5)) +
        labs(title = "Histogram of average promoter logCPM values",
             subtitle = "Colored by peak overlap"),
    Violin = ggplot(adata) +
        aes(x = PeakOverlap, y = logCPM) +
        geom_violin(aes(fill = PeakOverlap), scale = "area") +
        geom_boxplot(width = 0.07, fill = "grey", alpha = 0.75, outlier.alpha = 0) +
        geom_hline(yintercept = logcpm_threshold, linetype = "dashed") +
        scale_fill_hue(guide = "none") +
        coord_cartesian(ylim = quantile(a, c(0, 0.999))) +
        labs(title = "Violin plot of average promoter logCPM values",
             subtitle = "Grouped by peak overlap"))
ggprint(p)
tidy(lm(logCPM ~ PeakOverlap, data = adata))
```

The promoters that contain peaks clearly have a higher abundance on average than the promoters that do not. However, there is still significant overlap between the distributions. We use the logCPM distribution of peak-overlapping promoters to choose a low-count filter threshold that keeps 99% of such promoters, and then we keep *all* promoters that pass this threshold, regardless of whether they contain a called peak. This ensures that we capture most activity in any peak-containing promoters without relying directly on the peak calls. Thus, if a promoter contains a peak that was not called because it is only present in certain conditions, it is still likely to be included based on this filter criterion. This comes at the cost of potentially including many promoters with no real histone modification activity in them.

```{r filter_promoters}
nhood_sexp <- nhood_sexp[a >= logcpm_threshold,]
sexp <- sexp[mcols(sexp)$GeneID %in% mcols(nhood_sexp)$GeneID,]
```

# Preprocessing RNA-seq data

```{r rnaseq_preprocess}
rna_dge <- DGEList(assay(rnaseq_sexp, "counts"))
rna_dge$samples %<>% cbind(as(colData(rnaseq_sexp), "data.frame"))
nonzero <- rowSums(rna_dge$counts) > 0
if ("length" %in% assayNames(rnaseq_sexp)) {
    normMat <- assay(rnaseq_sexp, "length") %>% divide_by(exp(rowMeans(log(.))))
    normCounts <- rna_dge$counts/normMat
    present <- aveLogCPM(normCounts) >= -1
    lib.offsets <- log(calcNormFactors(normCounts[present,])) + log(colSums(normCounts))
    rna_dge$offset <- t(t(log(normMat)) + lib.offsets)
}
rna_N0_samples <- rna_dge$samples %$% { cell_type == "Naive" & days_after_activation == 0 }
rna_N0_logmean <- aveLogCPMWithOffset(rna_dge[,rna_N0_samples]) %>% set_names(rownames(rna_dge))
rna_N0_nonzero <- rowSums(rna_dge[,rna_N0_samples]$counts) > 0
```

# Exploratory Analysis

Now we create a DGEList from the counts. For the purposes of sva and dispersion calculation, we filter out all windows with an average count of less than 5.

```{r prepare_dgelist}
## Extract gene metadata and colapse lists
all.promoter.meta %<-% {
    rowRanges(nhood_sexp) %>%
        as.data.frame %>%
        rename(chr = seqnames) %>%
        select(-width, -strand) %>%
        ensure_atomic_columns()
}
all.window.meta %<-% {
    rowRanges(sexp) %>%
        as.data.frame %>%
        rename(chr = seqnames) %>%
        select(-width, -strand) %>%
        ensure_atomic_columns()
}
dge <- asDGEList(sexp)
count5_threshold <- aveLogCPM(5, lib.size = exp(mean(log(dge$samples$lib.size))))
dge %<>%
    assign_into(.$offset, NULL) %>%
    assign_into(.$genes, all.window.meta) %>%
    set_rownames(rownames(all.window.meta)) %>%
    .[aveLogCPM(.) >= count5_threshold,]
nhood_dge <- asDGEList(nhood_sexp) %>%
    assign_into(.$offset, NULL) %>%
    assign_into(.$genes, all.promoter.meta) %>%
    set_rownames(rownames(all.promoter.meta)) %>%
    .[aveLogCPM(.) >= count5_threshold,]
```

## Normalization

Normalization is a non-trivial issue for ChIP-Seq data. We will test three normalizations, one scaling normalization based on background read coverage, another based on read counts in the promoter regions, and finally a non-linear loess-curve normalization based on the promoter counts. Note that in addition to normalizing the windows directly, we normalize based on the total counts from each promoter and then apply those counts to the individual windows within each promoter, so that each promoter's windows are all normalized as a single unit. (This is mainly important for the loess normalization, which can apply a different offset to each feature.)

```{r compute_norm_factors}
# Compute these in parallel
bgnf %<-% normOffsets(bigbin_sexp, type = "scaling", weighted = FALSE, se.out = FALSE)
pnf %<-% normOffsets(nhood_sexp, type = "scaling", weighted = TRUE, se.out = FALSE)
wnf %<-% normOffsets(sexp, type = "scaling", weighted = TRUE, se.out = FALSE)
loff %<-% { normOffsets(nhood_sexp, type = "loess", se.out = FALSE) + mean(getOffset(dge)) }
nf_df <- data_frame(BGNormFactors = bgnf, PromoterNormFactors = pnf, WindowNormFactors = wnf)
colData(sexp)[colnames(nf_df)] <- as.list(nf_df)
sample_table[colnames(nf_df)] <- nf_df
assay(nhood_sexp, "offsets.loess") <- loff
assay(sexp, "offsets.loess") <- assay(nhood_sexp, "offsets.loess")[rowRanges(sexp)$GeneID,] %>% set_rownames(rownames(sexp))
```

We plot both scaling normalizations against all relevant experimental factors:

```{r plot_normfactors}
p <- list(ggduo(as.data.frame(colData(sexp)),
                columnsX = c("cell_type", "time_point", "donor_id", "totals"),
                columnsY = c("BGNormFactors", "PromoterNormFactors", "WindowNormFactors")),
          ggpairs(as.data.frame(colData(sexp)[c("totals", "BGNormFactors", "PromoterNormFactors", "WindowNormFactors")])))
ggprint(p)
```

Unlike for the genome-wide windows, the correlation between different normalization factors is much less clear, and there is not a clear association between the normalization factors and any known covariates.

We can see that the normalization based on individual windows is very similar to the normalization based on promoters, so we will discard the individual window-based normalization as redundant.

To test these normalizations, we will look at their effect on the dispersion estimation step. But first, we must generate the design matrix in order to estimate dispersions.

```{r build_design_matrix}
design <- model.matrix(~0 + group, sample_table) %>% strip_design_factor_names
colnames(design)
# Same design, but with an intercept, because sva requires it
design.int <- model.matrix(~1 + group, sample_table)
```


## SVA

To account for the variable effect of donor, efficiency bias, and as any other sources of systematic bias present in the data, we use SVA to estimate surrogate variables. We do so for each normalization method.

```{r sva}
dges <- list(
    BGNorm = dge %>% assign_into(.$samples$norm.factors, colData(sexp)$BGNormFactors),
    PromoterNorm = dge %>% assign_into(.$samples$norm.factors, colData(sexp)$PromoterNormFactors),
    LoessNorm = dge %>% assign_into(.$offset, assay(sexp, "offsets.loess")[rownames(.),]))
logcpms <- lapply(dges, cpmWithOffset, prior.count = 1)
logcpms %<>% lapply(. %>% .[rowVars(.) >= 1e-8,])

# Need a design with an intercept for sva. Also, filter out rows with (near) zero
# variance, because sva chokes on these
svobjs <- bplapply(logcpms, . %>% .[rowVars(.) >= 1e-8,] %>% sva(design.int))
# We are expecting at least 1 SV. If there are no SVs, then the downstream code
# needs changing.
for (i in names(svobjs)) {
    assert_that(svobjs[[i]]$n.sv > 0)
}
svmats <- lapply(svobjs, . %$% sv %>% cbind %>% add_numbered_colnames("SV"))
sv.designs <- lapply(svmats, . %>% cbind(design, .))
sv.designs.int <- lapply(svmats, . %>% cbind(design.int, .))
numsv.table <- sapply(svobjs, . %$% n.sv) %>% data_frame(NormType = names(.) , NumSV = .)
print(numsv.table)
p <- list()
for (i in names(svmats)) {
    d <- cbind(sample_table, svmats[[i]])
    p[[i]] <- ggduo(d,
                    columnsX = c("cell_type", "time_point", "donor_id", "totals"),
                    columnsY = c(colnames(svmats[[i]]))) +
        labs(title = "Covariates vs surrogate variables",
             subtitle = glue("For SVs from {i} normalization"))
}
ggprint(p)
```

These results seem to be spurious, with a single outlier sample dominating the SVA algorithm and throwing off the automatic detection of the number of surrogate variables. We will remove this outlier sample from the remainder of the analysis and run SVA again without it.

## Outlier Removal

First, we identify and remove the outlier.

```{r remove_outlier}
# Verify that the same outlier is identified in all SVA runs
all_sv <- do.call(cbind, svmats)
outlier <- apply(all_sv, 2, . %>% abs %>% which.max) %>% unique
assert_that(length(outlier) == 1)
good_samples <- colnames(sexp)[-outlier]

# Remove the outlier from all relevant objects
dge %<>% .[,good_samples]
dges %<>% lapply(. %>% .[,good_samples])
design %<>% .[good_samples,]
design.int %<>% .[good_samples,]
sample_table %<>% filter(SampleName %in% good_samples)
```

Then we re-run SVA on the remaining samples.

```{r sva_no_outliers}
logcpms <- lapply(dges, cpmWithOffset, prior.count = 1)
logcpms %<>% lapply(. %>% .[rowVars(.) >= 1e-8,])

# Need a design with an intercept for sva. Also, filter out rows with (near) zero
# variance, because sva chokes on these
svobjs <- bplapply(logcpms, . %>% .[rowVars(.) >= 1e-8,] %>% sva(design.int))
# We are expecting at least 1 SV. If there are no SVs, then the downstream code
# needs changing.
for (i in names(svobjs)) {
    assert_that(svobjs[[i]]$n.sv > 0)
}
svmats <- lapply(svobjs, . %$% sv %>% cbind %>% add_numbered_colnames("SV"))
sv.designs <- lapply(svmats, . %>% cbind(design, .))
sv.designs.int <- lapply(svmats, . %>% cbind(design.int, .))
numsv.table <- sapply(svobjs, . %$% n.sv) %>% data_frame(NormType = names(.) , NumSV = .)
print(numsv.table)
p <- list()
for (i in names(svmats)) {
    d <- cbind(sample_table, svmats[[i]])
    p[[i]] <- ggduo(d,
                    columnsX = c("cell_type", "time_point", "donor_id", "totals"),
                    columnsY = c(colnames(svmats[[i]]))) +
        labs(title = "Covariates vs surrogate variables",
             subtitle = glue("For SVs from {i} normalization"))
}
ggprint(p)
```

Both the background and promoter-based normalizations seem to produce reasonable results, while the loess normalization seems to produce some substantial outliers, which is cause for concern. Beyond that, it seems that some of the surrogate variables may be capturing the donor effects, while others seem to be confounded with the time point. This confounding is a potential concern, and we should be on the lookout for possible consequences of this in downstream analyses.

## Dispersion estimation

Now we estimate the dispersions with and without empirical Bayes shrinkage, with and without surrogate variables.

```{r estimate_disp_normtest}
dges.noebayes <- bpmapply(estimateDisp, y = dges, design = sv.designs, MoreArgs = list(prior.df = 0))
dges.noebayes.nosv <- bpmapply(estimateDisp, y = dges, MoreArgs = list(design = design, prior.df = 0))
dges <- bpmapply(estimateDisp, y = dges, design = sv.designs, MoreArgs = list(robust = TRUE))
dges.nosv <- bpmapply(estimateDisp, y = dges, MoreArgs = list(design = design, robust = TRUE))
# Hopefully save memory by re-sharing common parts after running in separate processes
for (i in names(dges)) {
    for (slot in c("counts", "genes")) {
        dges.noebayes[[i]][[slot]] <-
            dges.noebayes.nosv[[i]][[slot]] <-
            dges[[i]][[slot]] <-
            dges.nosv[[i]][[slot]] <-
            dge[[slot]]
    }
}
xlims <- lapply(c(dges, dges.nosv), . %$% AveLogCPM %>% range) %>%
    unlist %>% range %>% expand_range(mul = 0.05)
ylims <- lapply(c(dges, dges.nosv), . %$% c(quantile(tagwise.dispersion, c(0, 0.975)), trended.dispersion, common.dispersion) %>% range) %>%
    unlist %>% c(0) %>% range %>% sqrt %>% pmax(0) %>% expand_range(mul = 0.05)
```

We now inspect the dispersion plot for each of the normalizations.

```{r plot_disp_normtest}
p <- list()
for (i in names(dges)) {
    prior.df <- dges[[i]]$prior.df %>% median
    p[[i]] <- ggplotBCV(dges[[i]], rawdisp = dges.noebayes[[i]]) +
        coord_cartesian(xlim = xlims, ylim = ylims, expand = FALSE) +
        labs(title = glue("BCV Plot with {i}"),
             subtitle = glue("Prior d.f. = {format(prior.df, digits = 3)}"))
}
ggprint(p)
```

The peak-based normalizations and the loess normalization produce the smallest BCV estimates, while the background-based normalization has a set of spuriously high dispersion values. Based on these plots, the background normalization is clearly problematic, but there is no clear reason to prefer either of the promoter-based scaling normalization or loess normalization over the other.

We also inspect the BCV plot without SVA:

```{r plot_disp_normtest_nosv}
p <- list()
for (i in names(dges.nosv)) {
    prior.df <- dges.nosv[[i]]$prior.df %>% median
    p[[i]] <- ggplotBCV(dges.nosv[[i]], rawdisp = dges.noebayes.nosv[[i]]) +
        coord_cartesian(xlim = xlims, ylim = ylims, expand = FALSE) +
        labs(title = glue("BCV Plot with {i} and no SVA"),
             subtitle = glue("Prior d.f. = {format(prior.df, digits = 3)}"))
}
ggprint(p)
```

Not only are the BCV values higher without SVA, the BCV also trends upward with abundance rather than downward as is typical. In addition, we can now clearly see the spurious high-dispersion subset in all three plots, whereas it was previously only visible in the plot for background normalization. These BCV plots are indicative of the likely presence of unmodeled batch effects and underscore the importance of SVA for this data set. In any case, we can quantify the effect of SVA by looking at the distribution of changes in BCV when the surrogate variables are added to the model.

```{r sva_disp_effect}
disptable <- lapply(names(dges), function(i) {
    data_frame(NormType = i, Promoter = rownames(dges[[i]]),
               DispSVA = dges[[i]]$tagwise.dispersion,
               DispNoSVA = dges.nosv[[i]]$tagwise.dispersion)
}) %>% do.call(what = rbind) %>%
    mutate(BCV_SVA = sqrt(DispSVA),
           BCV_NoSVA = sqrt(DispNoSVA),
           BCV_Change = BCV_SVA - BCV_NoSVA)
# These aren't used any more and take up a lot of memory, so delete
# them.
rm(dges.nosv, dges.noebayes, dges.noebayes.nosv); invisible(gc())
disptable %>% group_by(NormType) %>% do({
    summary(.$BCV_Change) %>% unclass %>% rbind %>% as_data_frame
}) %>% inner_join(numsv.table, ., by = "NormType")
bcv_upper_limit <- disptable %>% select(BCV_SVA, BCV_NoSVA) %>% unlist %>% quantile(.999)
ggplot(disptable) +
    aes(x = NormType, y = BCV_NoSVA) +
    geom_violin(aes(fill = NormType), scale = "area") +
    geom_boxplot(width = 0.07, fill = "grey", alpha = 0.75, outlier.alpha = 0) +
    scale_fill_hue(guide = "none") +
    coord_cartesian(ylim = c(0, bcv_upper_limit)) +
    labs(title = "BCV estimates without SVA") +
    xlab("Normalization Type") +
    ylab("BCV")
ggplot(disptable) +
    aes(x = NormType, y = BCV_SVA) +
    geom_violin(aes(fill = NormType), scale = "area") +
    geom_boxplot(width = 0.07, fill = "grey", alpha = 0.75, outlier.alpha = 0) +
    scale_fill_hue(guide = "none") +
    coord_cartesian(ylim = c(0, bcv_upper_limit)) +
    labs(title = "BCV estimates with SVA") +
    xlab("Normalization Type") +
    ylab("BCV")
ggplot(disptable) +
    aes(x = NormType, y = BCV_Change) +
    geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
    geom_violin(aes(fill = NormType), scale = "area") +
    geom_boxplot(width = 0.07, fill = "grey", alpha = 0.75, outlier.alpha = 0) +
    scale_fill_hue(guide = "none") +
    coord_cartesian(ylim = quantile(disptable$BCV_Change, c(.001, .999))) +
    labs(title = "Effect of SVA on BCV estimates") +
    xlab("Normalization Type") +
    ylab("Change in BCV with SVA")
```

We can see that the median change in BCV is around -0.1 for the background-based normalization and -0.15 for the other normalizations. Next, we examine the effect of each normalization on the MDS plot.

## MDS Plots

We compute the MDS coordinates after subtracting the effects of the surrogate variables for each normalization. The result is a plot showing the variation attributable to sources other than those unknown batch effects. To demonstrate the difference that batch subtraction makes, we also generate the same plots from the uncorrected data.

```{r compute_mds_normtest}
bcdata <- mapply(function(dge, des) {
    sv.cols <- colnames(des) %>% .[str_detect(., "^SV\\d+$")]
    assert_that(length(sv.cols) > 0)
    v <- voomWithOffset(dge, des)
    v$E <- suppressMessages(subtractCoefs(v$E, des, coefsToSubtract = sv.cols))
    v
}, dge = dges, des = sv.designs.int, SIMPLIFY = FALSE)
prep.mds <- function(x) {
    mds <- suppressPlot(plotMDS(x))
    mds.distances <- mds %$% distance.matrix %>% as.dist
    df <- mds.distances %>%
    {suppressWarnings(cmdscale(., k = ncol(x)-1))} %>%
        add_numbered_colnames(prefix = "Dim") %>%
        as.data.frame %>%
        cbind(sample_table)
    # Use Naive D0 as the reference group, and flip the signs of each dimension
    # such that the mean of this group is negative. This makes it more likely that
    mdscols <- colnames(df) %>% .[str_detect(., "Dim\\d+")]
    needflip <- df %>% filter(group == "NaiveDay0") %>%
        .[mdscols] %>% colMeans %>% is_greater_than(0)
    for (i in mdscols[needflip]) {
        df[[i]] %<>% multiply_by(-1)
    }
    df
}
mdstabs <- lapply(bcdata, prep.mds)
mdstabs.nosv <- lapply(dges, prep.mds)
ggmds <- function(x) {
     ggplot(x %>% arrange(cell_type, time_point, donor_id)) +
        aes(x = Dim1, y = Dim2, label = SampleName, color = time_point,
            shape = cell_type, linetype = donor_id, group = cell_type:donor_id) +
        geom_encircle(aes(group = time_point:cell_type, color = NULL, fill = time_point), s_shape = 0.75, expand = 0.05, color = NA, alpha = 0.2) +
        geom_path(color = hcl(c = 0, l = 45), aes(color = NULL)) +
        # geom_point(   size = 4) +
        geom_point(aes(size = totals)) +
        scale_shape_manual(values = c(Naive = 16, Memory = 17)) +
        scale_fill_hue(l = 55) +
        scale_linetype_manual(values = c("solid", "dashed", "dotdash", "twodash")) +
        guides(shape = guide_legend(order = 1, ncol = 2, override.aes = list(size = 4, color = hcl(c = 0, l = 80), fill = hcl(c = 0, l = 55))),
               fill = guide_legend(order = 2, ncol = 2, override.aes = list(shape = 16, size = 4)),
               color = guide_legend(order = 2, ncol = 2),
               linetype = guide_legend(order = 3, ncol = 2),
               size = guide_legend(order = 4, title = "total_reads")) +
        coord_equal()
}
p12 <- p23 <- p12.nosv <- p23.nosv <- list()
for (i in names(mdstabs)) {
    p12[[i]] <- ggmds(mdstabs[[i]]) +
        labs(title = "MDS Principal Coordinates 1 & 2",
             subtitle = glue("With {i} normalization; SVs subtracted")) +
        coord_equal()
    p23[[i]] <- p12[[i]] + aes(x = Dim2, y = Dim3) +
        labs(title = "MDS Principal Coordinates 2 & 3")
    p12.nosv[[i]] <- ggmds(mdstabs.nosv[[i]]) +
        labs(title = "MDS Principal Coordinates 1 & 2",
             subtitle = glue("With {i} normalization; SVs not subtracted")) +
        coord_equal()
    p23.nosv[[i]] <- p12.nosv[[i]] + aes(x = Dim2, y = Dim3) +
        labs(title = "MDS Principal Coordinates 2 & 3")
}
```

```{r mds_pc12}
ggprint(p12)
```

```{r mds_pc23}
ggprint(p23)
```

The promoter-based normalizations produce the cleanest, most interpretable MDS plots by far, with both naive and memory cells tracing parallel arcs over time. The background normalization is clearly dominated by a single outlier in the first principal coordinate, while the 2nd and 3rd PCs mirror PC1 and PC2 from the promoter-based normalizations. These results definitely favor promoter-based normalization with SVA as the best modelling strategy for this data, but again, the two normalization strategies, scaling and loess, preduce very similar results.

## MDS plots without subtracting SV effects

Now, we repeat the same plots as above, but with no subtraction of surrogate variable effects from the data.

```{r mds_pc12_NoSV}
ggprint(p12.nosv)
```

```{r mds_pc23_NoSV}
ggprint(p23.nosv)
```

Without the surrogate variables, the MDS plots look are more or less uninterpretable, with no clean separation between groups. The outlier that was previously visible only in the background normalization is now visible in all 3 plots. This outlier seems likely to be the cause of the artifacts in the BCV plots earlier. This underscores the importance of modelling unknown sources of variation in the data using SVA. These unknown sources could include ChIP efficiency bias, GC bias, and other technical variables in the ChIP-Seq process that have nothing to do with the biology of the experiment. Because the donor ID was not included in the design, inter-donor variability could also be included in the surrogate variables.

Based on all of the above, the promoter-based normalizations, both scaling and loess, perform very similarly. Since the scaling normalization is simpler and requires less stringent assumptions about the data, we will move forward using this normalization.

TODO Rewrite the above analysis to match the new plots. But Promoter norm is still the choice.

# Clustering Promoters

We now compute the average group abundances of all windows after surrogate variable subtraction, using our chosen normalization.

```{r cpm_batch_correct}
dgefull <- asDGEList(sexp) %>%
    assign_into(.$offset, NULL) %>%
    assign_into(.$genes, all.window.meta) %>%
    set_rownames(rownames(all.window.meta)) %>%
    .[,good_samples]
dgefull$samples$norm.factors <- dges$PromoterNorm$samples$norm.factors
design <- sv.designs$PromoterNorm
v <- voomWithOffset(dgefull, design)
fit <- lmFit(v, design)
group_logCPM_matrix <- fit$coefficients[,levels(sample_table$group)]
group_logCPM <- group_logCPM_matrix %>% cbind(all.window.meta) %>%
    gather(key=Group, value=logCPM, !!levels(sample_table$group))
group_logCPM_byOffset <- group_logCPM %>%
    select(GeneID, offset, Group, logCPM) %>%
    arrange(Group, GeneID, offset) %>%
    spread(key = offset, value = logCPM)
```

Next, we pick just the Naive Day 0 group and cluster the promoters based on abundance differences across offsets.

```{r kmeans_initial_ND0}
ND0_logCPM_centered <- group_logCPM_byOffset %>%
    filter(Group == "NaiveDay0") %>%
    set_rownames(.$GeneID) %>%
    select(-GeneID, -Group) %>%
    as.matrix %>%
    subtract(rowMeans(.))
km <- ND0_logCPM_centered %>% kmeans(centers = 6, iter.max = 1000, nstart = 10, algorithm = "MacQueen")
cl_df <- tidy(km, col.names=colnames(km$centers)) %>% gather(key = "Offset", value = "logCPM", !!colnames(km$centers)) %>%
    mutate(Offset = as.numeric(as.character(Offset)))
offset_step <- cl_df$Offset %>% unique %>% sort %>% diff %>% unique
assert_that(length(offset_step) == 1)
cl_path_df <- cl_df %>% group_by(cluster) %>%
    do(tibble(
        Offset = rep(.$Offset, each = 2) + c(-1, 1) * offset_step/2,
        logCPM = rep(.$logCPM, each = 2)
    )) %>% ungroup
ggplot(cl_path_df) +
    aes(x = Offset, y = logCPM,
        group = cluster, color = cluster) +
    geom_vline(xintercept = 0, linetype = "dotted", alpha = 0.5) +
    geom_path() +
    facet_grid(cluster ~ .) +
    ggtitle("K-means cluster averages") +
    xlab("Position relative to TSS (bp)") +
    ylab("Relative coverage depth (logCPM)") +
    guides(color=FALSE)
```

Seeing that there is definitely something interesting going on, we proceed to more principled ways of choosing the number of clusters.

```{r num_clusters}
# K-means scree plot
scree_data <- data.frame(k = 1:15)
km_list <- bpmapply(kmeans, centers = scree_data$k, MoreArgs = list(x = ND0_logCPM_centered, iter.max = 1000, nstart = 10, algorithm = "MacQueen"), SIMPLIFY = FALSE)
scree_data$wss <- sapply(km_list, . %$% tot.withinss)
ggplot(scree_data) + aes(x = k, y = wss) +
    geom_line(alpha = 0.5) + geom_point() +
    ggtitle("K-means scree plot")
```

It seems that there is no clear elbow in the scree plot, which means we are not really sure which value of k is the most appropriate.

# PCA plots

To get a different look at the data, let's perform principal component analysis.

```{r PCA}
prc <- prcomp(ND0_logCPM_centered)
prc_promoter_df <- prc$x %>%
    as.data.frame %>% rownames_to_column("GeneID") %>% as_tibble %>%
    mutate(Cluster = factor(km$cluster[GeneID])) %>%
    select(GeneID, Cluster, everything())
lim <- max(abs(prc$x))
p <- list(
    pc12 = ggplot(data = prc_promoter_df %>% arrange(PC3),
                  aes(x = PC1, y = PC2, color = Cluster)) +
        geom_point() +
        coord_fixed() +
        xlim(-lim, lim) + ylim(-lim, lim) +
        ggtitle("PCA PC1&2 Colored by Cluster",
                "Z-order determined by PC3"),
    # This setup yields a 90-degree rotation about the vertical axis relative to the previous plot
    pc23 = ggplot(data = prc_promoter_df %>% arrange(-PC1),
                  aes(x = PC3, y = PC2, color = Cluster)) +
        geom_point() +
        coord_fixed() +
        scale_color_discrete(drop = FALSE) +
        xlim(-lim, lim) + ylim(-lim, lim) +
        ggtitle("PCA PC2&3 Colored by Cluster",
                "Z-order determined by PC1"))
ggprint(p)
```

It looks like the data might actually form a unimodal ellipsoid in the first 3 PCs, which would certainly explain the difficulty in selecting a value of k for k-means clustering. To verify this, we can make a 3-D scatter plot.

```{r PCA_3D}
p <- plot_ly(prc_promoter_df, x = ~PC1, y = ~PC2, z = ~PC3, color = ~Cluster, size = I(3)) %>%
    add_markers()
p
```

# Relating expression to promoter behavior

Now we max a boxplot of expression values for each k-means cluster.

```{r kmeans_expr_boxplot}
expr_by_cluster <-
    tibble(Cluster = factor(km$cluster),
           GeneID = names(km$cluster)) %>%
    mutate(logCPM = rna_N0_logmean[.$GeneID],
           nonzero = rna_N0_nonzero[.$GeneID])
p <- ggplot(expr_by_cluster %>% filter(nonzero)) +
    aes(x = Cluster, y = logCPM) +
    geom_boxplot(aes(color = Cluster), fill = NA) +
    geom_violin(aes(fill = Cluster)) +
    guides(color = FALSE, fill = FALSE)
ggprint(p)
```

---
title: "Exploration of CD4 ChIP-Seq Dataset"
author: "Ryan C. Thompson"
date: '`r gsub("\\s+", " ", format(Sys.time(), "%B %e, %Y"))`'
output:
  html_document: default
  html_notebook: default
subtitle: '`r paste0("For histone mark ", params$histone_mark)`'
params:
  basedir:
    value: /home/ryan/Projects/CD4-csaw
  histone_mark:
    value: H3K27me3
  window_size:
    value: 500bp
  fragment_length:
    value: 147bp
  bigbin_size:
    value: 10kbp
---

# Preliminary Setup

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE, retina=2, cache=TRUE, autodep=TRUE,
                      cache.extra = list(params=params), 
                      # https://github.com/yihui/knitr/issues/572
                      cache.lazy=FALSE,
                      fig.height=8, fig.width=8,
                      cache.path = paste0(file.path(params$basedir, "cache", "chipseq-explore", params$histone_mark), .Platform$file.sep))

```

First we load the necessary libraries, along with a set of utility functions.

```{r load_packages, message=FALSE, cache=FALSE}
library(stringr)
library(magrittr)
library(openxlsx)
library(SummarizedExperiment)
library(dplyr)
library(edgeR)
library(limma)
library(csaw)
library(sva)
library(ggplot2)
library(scales)
library(GGally)
library(ggalt)
library(ggthemes)
library(splines)
library(reshape2)
library(assertthat)
library(ggfortify)
library(broom)
library(ks)
library(RColorBrewer)
library(Rtsne)

library(BSgenome.Hsapiens.UCSC.hg38)

library(doParallel)
ncores <- getOption("mc.cores", default=parallel::detectCores(logical = FALSE))
options(mc.cores=ncores)
registerDoParallel(cores=ncores)
library(BiocParallel)
register(DoparParam())

options(future.globals.maxSize=4 * 1024^3)
library(future)
plan(multicore)

source(file.path(params$basedir, "scripts/utilities.R"))

# Required in order to use DGEList objects with future
length.DGEList <- function(x) {
    length(unclass(x))
}
```

# Data Loading and Preprocessing

First we load the consensus peaks called from the reads pooled from all samples. This consensus peak set is not biased toward or against any sample or condition, and therefore the peak significance is expected to be independent of any differential binding in that peak.

```{r load_peaks}
peakfile <- file.path(
    params$basedir, "peak_calls", "epic_hg38.analysisSet",
    str_c(params$histone_mark, "_condition.ALL_donor.ALL"),
    "peaks_noBL_IDR.narrowPeak")
allpeaks <- {
    read.narrowPeak(peakfile) %>% as("GRanges") %>%
        assign_into(seqinfo(.), seqinfo(BSgenome.Hsapiens.UCSC.hg38)[seqlevels(.)])
}
```

Now we'll load the ChIP-seq read count data set from RDS files containing SummarizedExperiment objects, and modify them to use the sample names as column names. We also ensure that the column order is identical between the two objects. Lastly, we filter out any windows with fewer than one count per sample. This is a very mild filtering criterion, but it often eliminates many windows, greatly easing the subsequent computational burden of computing the *real* filtering threshold.

```{r load_counts}
sexpfile <- 
    file.path(params$basedir, "saved_data",
              with(params, sprintf("csaw-counts-%s-windows-%s-reads-%s.RDS", window_size, fragment_length, histone_mark)))
bigbin.sexpfile <- file.path(params$basedir, "saved_data",
                             with(params, sprintf("csaw-counts-%s-bigbins-%s.RDS", bigbin_size, histone_mark)))
bigbin.sexp <- readRDS(bigbin.sexpfile)
full.sexp <- readRDS(sexpfile)
colnames(full.sexp) <- colData(full.sexp)$SampleName
colnames(bigbin.sexp) <- colData(bigbin.sexp)$SampleName
# Ensure identical column order
bigbin.sexp %<>% .[,colnames(full.sexp)]
assert_that(all(colnames(full.sexp) == colnames(bigbin.sexp)))
sexp <- full.sexp %>% .[rowSums(assay(.)) >= ncol(.),]
# Exepected number of counts per read, based on overlapping multiple windows. 
# NOTE: Assumes windows exactly tile the genome (no overlaps, no gaps).
colData(sexp)$CountDupFactor <- (colData(sexp)$ext - 1) / median(width(rowRanges(sexp))) + 1
```

We extract the sample metadata from the SummarizedExperiment. We set all factors to use a sum-to-zero variant of the treatment-contrast coding, which will ease the subtraction of batch effects later.

```{r extract_samplemeta}
sample.table <- colData(sexp) %>%
    as.data.frame %>% autoFactorize %>%
    mutate(days_after_activation=time_point %>% str_extract("\\d+$") %>% as.numeric(),
           time_point=factor(days_after_activation) %>% `levels<-`(sprintf("D%s", levels(.))),
           group=interaction(cell_type, time_point, sep="")) %>% 
    autoFactorize %>%
    set_rownames(colnames(sexp))
for (i in names(sample.table)) {
    if (is.factor(sample.table[[i]]) && nlevels(sample.table[[i]]) > 1) {
        sample.table[[i]] %<>% C(code_control_named(levels(.)))
    }
}
```

# Peak and Window Filtering

We begin by selecting only peaks  with an IDR value of 0.05 or less.
```{r initial_filter_peaks}
idr.threshold <- 0.05
genome.size <- seqlengths(seqinfo(allpeaks)) %>% as.numeric %>% sum
peaks <- allpeaks[allpeaks$qValue >= -log10(idr.threshold)]
pct.covered <- width(peaks) %>% sum %>% divide_by(genome.size) %>% multiply_by(100)
mean.pct.reads <- sexp %>% subsetByOverlaps(peaks) %>% assay("counts") %>%
    colSums %>% divide_by(colData(sexp) %$% {totals * CountDupFactor}) %>% multiply_by(100) %>%
    mean
message(sprintf("Selected %i peaks at an IDR threshold of %.3g, with an average width of %.0f nucleotides and covering a total of %.3g%% of the genome, containing on average %.3g%% of reads", length(peaks), idr.threshold, mean(width(peaks)), pct.covered, mean.pct.reads))
```

Now we need a strategy to filter out uninformative windows representing background regions of the genome where no specific binding is observed. First, we examine the overall distribution of average logCPM values, as well as the average logCPM distribution within called peaks:

```{r compute_aveLogCPM}
a %<-% aveLogCPM(asDGEList(sexp), prior.count = 2)
peak.overlap <- overlapsAny(sexp, peaks)
a.peaks <- a[peak.overlap]
```

```{r plot_aveLogCPM}
adata <- data.frame(logCPM=a, PeakOverlap=peak.overlap)
p <- list(
    Histogram=ggplot(adata) +
        aes(x=logCPM, fill=PeakOverlap) +
        geom_histogram(aes(y=100*(..count..)/sum(..count..)), binwidth=0.1, boundary=0) +
        xlab("Average logCPM") + ylab("Percent of windows in bin") +
        coord_cartesian(xlim=quantile(a, c(0, 0.999)), ylim=c(0,3)) +
        labs(title="Histogram of average window logCPM values",
             subtitle="Colored by peak overlap"),
    Violin=ggplot(adata) +
        aes(x=PeakOverlap, y=logCPM) +
        geom_violin() + 
        geom_tufteboxplot(median.type = "line", whisker.type = 'line', hoffset = 0, width = 3) +
        labs(title="Violin plot of average window logCPM values",
             subtitle="Grouped by peak overlap"))
ggprint(p)
summary(lm(logCPM ~ PeakOverlap, data=adata))
```

From the linear model and violin plot, we can see that peaks are clearly significantly enriched for high-abundance windows relative to background regions. However, the histogram shows that a purely count-based filter is not desirable, because any threshold still leaves substantial high-count windows that do no overlap peaks.This is because the peaks represent only a small fraction of the genome and the random variation in background coverage depth is at least as large as the difference between peaks and unbound regions. Hence, we will simply select all windows that overlap called peaks. For this purpose, we will select a larger set of peaks using a more relaxed IDR threshold in order to maximize the probability of including peaks that are present in only one or a few conditions and are therefore more weakly represented in the all-sample consensus. The trade-off of including more false positive peaks is acceptable here, since false positive peaks are not expected to show evidence of differential binding.

```{r filter_peaks}
idr.threshold <- 0.2
peaks <- allpeaks[allpeaks$qValue >= -log10(idr.threshold)]
pct.covered <- width(peaks) %>% sum %>% divide_by(genome.size) %>% multiply_by(100)
mean.pct.reads <- sexp %>% subsetByOverlaps(peaks) %>% assay("counts") %>%
    colSums %>% divide_by(colData(sexp) %$% {totals * CountDupFactor}) %>% multiply_by(100) %>%
    mean
message(sprintf("Selected %i peaks at an IDR threshold of %.3g, with an average width of %.0f nucleotides and covering a total of %.3g%% of the genome, containing on average %.3g%% of reads", length(peaks), idr.threshold, mean(width(peaks)), pct.covered, mean.pct.reads))
```

```{r filter_windows_by_peak_overlap}
sexp %<>% subsetByOverlaps(peaks)
```

Lastly, we plot the resulting aveLogCPM distribution.

```{r replot_aveLogCPM}
a <- aveLogCPM(asDGEList(sexp), prior.count = 2)
p <- ggplot(data.frame(logCPM=a)) +
    aes(x=logCPM) +
    geom_histogram(aes(y=100*(..count..)/sum(..count..)), binwidth=0.1, boundary=0) +
    xlab("Average logCPM") + ylab("Percent of windows in bin") +
    coord_cartesian(xlim=quantile(a, c(0, 0.999)))
ggprint(p)
```

# Exploratory Analysis

Now we create a DGEList from the counts.

```{r prepare_dgelist}
## Extract gene metadata and colapse lists
all.window.meta <- rowRanges(sexp) %>% as.data.frame %>%
    select(-width, -strand) %>% rename(chr=seqnames)
# Convert list columns to character vectors
all.window.meta[] %<>% lapply(function(x) if (is.list(x)) sapply(x, str_c, collapse=",") else x)
rownames(all.window.meta) <- all.window.meta %$% sprintf("%s:%s-%s", chr, start, end)
dge <- asDGEList(sexp) %>% 
    assign_into(.$offset, NULL) %>%
    assign_into(.$genes, all.window.meta) %>%
    set_rownames(rownames(all.window.meta))
```

## Normalization

Normalization is a non-trivial issue for ChIP-Seq data. We will test three normalizations, one scaling normalization based on background read coverage, another based on coverage in the selected peak regions, and finally a non-linear loess-curve normalization. We also compute the number and fraction of reads in peaks for each sample.

```{r compute_norm_factors_and_frip}
# Compute these in parallel
bgnf %<-% normOffsets(bigbin.sexp, type="scaling", weighted=FALSE)
pnf %<-% normOffsets(sexp, type="scaling", weighted=TRUE)
loff %<-% { normOffsets(sexp, type="loess") + mean(getOffset(dge)) }
sample.table$BGNormFactors <- colData(sexp)$BGNormFactors <- bgnf
sample.table$PeakNormFactors <- colData(sexp)$PeakNormFactors <- pnf
assay(sexp, "offsets.loess")  <- loff

sample.table$RiP <- colData(sexp)$RiP <- assay(sexp) %>%
    colSums %>%
    divide_by(sample.table$CountDupFactor)
sample.table$FRiP <- colData(sexp)$FRiP <- colData(sexp) %$% { RiP / totals }
```

We plot both normalizations against all relevant experimental factors:

```{r plot_frip}
p <- list(ggduo(as.data.frame(colData(sexp)),
                columnsX=c("cell_type", "time_point", "donor_id", "totals", "FRiP"),
                columnsY=c("BGNormFactors", "PeakNormFactors")),
         ggpairs(as.data.frame(colData(sexp)[c("totals", "RiP", "FRiP", "BGNormFactors", "PeakNormFactors")])))
ggprint(p)
```

The strongest associations are between the FRiP values and both normalization factors, with the peak-based normalization factors being positively correlated with FRiP and the background normalization being negatively correlated. This indicates that the peak-based normalization factors are counteracting differences in pulldown efficiency between samples, while composition normalizationfactors are preserving, and perhaps even reinforcing these differences. This is the expected behavior for both normalization methods. There is also a visible, but weaker, negative correlation between total read counts and FRiP: sample with more total reads tend to have a greater fraction of reads not overlapping peaks.

To test these normalizations, we will look at their effect on the dispersion estimation step. But first, we must generate the design matrix in order to estimate dispersions.

```{r build_design_matrix}
FRiP.NS <- ns(sample.table$FRiP, df=3, intercept = FALSE)
design.NoFRiP <- model.matrix(~0 + group + donor_id, sample.table, strip.prefixes = TRUE)
design <- model.matrix(~0 + group + donor_id + FRiP.NS, sample.table, strip.prefixes = TRUE)
colnames(design)
```

## Dispersion estimation

Now we estimate the dispersions with and without empirical Bayes shrinkage. We also try an additional normalization based on only the windows that are both peak-overlapping and have a mean count greater than 5.

```{r estimate_disp_normtest}
count.threshold <- 5
filter.threshold <- aveLogCPM(count.threshold, lib.size=mean(dge$samples$lib.size))
filt <- aveLogCPM(dge) >= filter.threshold
message(sprintf("Excluding %i out of %i peak-overlapping windows (%.3g%%) with average count below %s.",
                sum(filt == FALSE), length(filt), 100*(1-mean(filt)), count.threshold))
dgefilt <- dge[filt,]
dges <- list(
    BGNorm=dgefilt %>% assign_into(.$samples$norm.factors, colData(sexp)$BGNormFactors),
    PeakNorm=dgefilt %>% assign_into(.$samples$norm.factors, colData(sexp)$PeakNormFactors),
    PeakHANorm=dgefilt %>% calcNormFactors(),
    LoessNorm=dgefilt %>% assign_into(.$offset, assay(sexp, "offsets.loess")[filt,]))
dges.noebayes <- lapply(dges, function(d) future(estimateDisp(d, design, prior.df=0)))
dges <- lapply(dges, function(d) future(estimateDisp(d, design, robust=TRUE)))
dges.noebayes %<>% values
dges %<>% values
# Hopefully save memory by re-sharing the count matrix after running in separate processes
for (i in names(dges)) {
    for (slot in c("counts", "genes")) {}
    dges.noebayes[[i]][[slot]] <- dges[[i]][[slot]] <- dgefilt[[slot]]
}
```

We now inspect the dispersion plot for each of the normalizations.

```{r plot_disp_normtest}
xlims <- lapply(dges, . %$% AveLogCPM %>% range) %>%
    unlist %>% range %>% expand_range(mul=0.05)
ylims <- lapply(dges, . %$% c(tagwise.dispersion, trended.dispersion, common.dispersion) %>% range) %>%
    unlist %>% range %>% sqrt %>% pmax(0) %>% expand_range(mul=0.05)
p <- list()
for (i in names(dges)) {
    prior.df <- dges[[i]]$prior.df %>% median
    p[[i]] <- ggplotBCV(dges[[i]], rawdisp=dges.noebayes[[i]]) +
        coord_cartesian(xlim = xlims, ylim=ylims) +
        labs(title=sprintf("BCV Plot with %s", i),
             subtitle=sprintf("Prior d.f. = %.3g", prior.df))
}
ggprint(p)
```

All the normalizations seem to perform very similarly here except for the loess normalization, which results in much a larger prior d.f. For this reason, we are inclined to distrust the loess normalization.

Next, we examine the effect of each normalization on the MDS plot.

## MDS Plots

We compute the MDS coordinates after subtracting the batch effects of both FRiP and donor_id. The result is a plot showing the variation attributable to sources other than those batch effects. To demonstrate the result of subtracting the FRiP effect, we also do the same with a design that does not include the FRiP effect.

```{r compute_mds_normtest}
batch.cols <- colnames(design) %>% .[str_detect(., "^FRiP\\.NS|^D\\d+\\.vs\\.D\\d+$")]
bcdata <- dges %>% 
    bplapply(. %>% voomWithOffset(design=design) %>%
                 assign_into(.$E, subtractCoefs(.$E, design, coefsToSubtract=intersect(colnames(design), batch.cols))))
bcdata.NoFRiP <- dges %>% 
    bplapply(. %>% voomWithOffset(design=design.NoFRiP) %>%
                 assign_into(.$E, subtractCoefs(.$E, design.NoFRiP, coefsToSubtract=intersect(colnames(design.NoFRiP), batch.cols))))
prep.mds <- function(x) {
    mds <- suppressPlot(plotMDS(x))
    mds.distances <- mds %$% distance.matrix %>% as.dist
    mds.distances %>% 
        {suppressWarnings(cmdscale(., k=ncol(x)-1))} %>% 
        add.numbered.colnames(prefix="Dim") %>%
        as.data.frame %>%
        cbind(sample.table)
}
mdstabs <- bplapply(bcdata, prep.mds)
mdstabs.NoFRiP <- bplapply(bcdata.NoFRiP, prep.mds)
ggmds <- function(x) {
     ggplot(x %>% arrange(cell_type, time_point, donor_id)) +
        aes(x=Dim1, y=Dim2, label=SampleName, color=time_point,
            shape=cell_type, linetype=donor_id, group=cell_type:donor_id) +
        geom_encircle(aes(group=time_point:cell_type, color=NULL, fill=time_point), s_shape=0.75, expand=0.05, color=NA, alpha=0.2) +
        geom_path(color=hcl(c=0, l=45), aes(color=NULL)) +
        # geom_point(   size=4) +
        geom_point(aes(size=totals)) +
        scale_shape_manual(values=c(Naive=16, Memory=17)) +
        scale_fill_hue(l=55) +
        scale_linetype_manual(values=c("solid", "dashed", "dotdash", "twodash")) +
        guides(shape = guide_legend(order=1, ncol=2, override.aes = list(size=4, color=hcl(c=0, l=80), fill=hcl(c=0, l=55))),
               fill = guide_legend(order=2, ncol=2, override.aes = list(shape = 16, size=4)),
               color = guide_legend(order=2, ncol=2),
               linetype = guide_legend(order=3, ncol=2),
               size = guide_legend(order=4, title = "total_reads")) +
        coord_equal()
}
p12 <- p23 <- p12.nf <- p23.nf <- list()
for (i in names(mdstabs)) {
    p12[[i]] <- ggmds(mdstabs[[i]]) +
        labs(title="MDS Principal Coordinates 1 & 2",
             subtitle=sprintf("With %s normalization; donor & FRiP effects subtracted", i))
    p23[[i]] <- p12[[i]] + aes(x=Dim2, y=Dim3) +
        labs(title="MDS Principal Coordinates 2 & 3")
    p12.nf[[i]] <- ggmds(mdstabs.NoFRiP[[i]]) +
        labs(title="MDS Principal Coordinates 1 & 2",
             subtitle=sprintf("With %s normalization; donor effects subtracted", i))
    p23.nf[[i]] <- p12.nf[[i]] + aes(x=Dim2, y=Dim3) +
        labs(title="MDS Principal Coordinates 2 & 3")
}
```

```{r mds_pc12}
ggprint(p12)
```

```{r mds_pc23}
ggprint(p23)
```

All 4 normalization methods produce similar looking plots for dimensions 1 and 2, in which the day 0 and day 14 samples cluster together on one side while days 1 and 5 cluster together on the other side. In addition, all normalizations give a roughly monotonic progression with time for dimension 3. This makes biological sense, suggesting that there is one set of peaks that are modified from their resting state during activation and then return to their previous state at day 14, while another smaller set of peaks undergo permanent changes between day 1 and day 5. In any case, the MDS plots do not seem to strongly favor or eliminate any of the normalizations. Based on the BCV and MDS plots, any of the proposed scaling normalizations is appropriate. The "high abundance windows within peaks" normalization method is the simplest to implement, since it is computed from only the count data of the windows being analyzed and does not rely on external data, such as filtered-out low-count windows or a separate count table for large bins. Hence, this normalization method will be used going forward.

## MDS plots without subtracting FRiP effects

Now, we repeat the same plots as above, but with no subtraction of FRiP effects from the data.

```{r mds_pc12_NoFRiP}
ggprint(p12.nf)
```

```{r mds_pc23_NoFRiP}
ggprint(p23.nf)
```

Without subtracting the effects of FRiP, the results are very different. The only normalizations with any clear separation between time points in the first two dimensions are the background normalization, which weakly separates days 0 and 14 from days 1 and 5 along dimension 1; and the lowess normalization, which separates days 0 and 1 from days 5 and 14 along dimension 2. Furthermore, the 3 types of normalization (peak, background, and loess) all produces markedly different MDS plots, in contrast to the broadly similar plots above. From this, we conclude that adding FRiP as a covariate is justified.

## MA plots

Now we examine the effect of each normalization on the MA plots between samples. We will order the samples from smallest to largest ratio between the peak and background normalization factors, and then pair them up with the opposite: first with last, second with second-to-last, and so on. This will yield a range of MA plots, some between samples with very different normalizations and some with very similar normalizations.

```{r prep_ma_plots}
colData(sexp)$nf.logratio <- colData(sexp) %$% log2(PeakNormFactors/BGNormFactors)
middle.samples <- colData(sexp)$nf.logratio %>% abs %>% order
bn.higher.samples <- colData(sexp)$nf.logratio %>% order
pn.higher.samples <- rev(bn.higher.samples)

logcpm <- cpm(dgefilt, log=TRUE, prior.count=0.5)
# The same measure used for the loess normalization
AveLogCPM <- aveLogCPM(dgefilt, dispersion = 0.05, prior.count = 0.5)
logcpm.loess <- cpmWithOffset(dges$LoessNorm, log=TRUE, prior.count=0.5)
bigbin.logcpm <- cpm(asDGEList(bigbin.sexp), log=TRUE, prior.count=0.5)

getLineData <- function(s1, s2) {
    c(BG="BGNorm",
      Peaks="PeakNorm",
      PeaksHA="PeakHANorm") %>%
        sapply(. %>% {dges[[.]]$samples$norm.factors} %>% log2 %>% {.[s2] - .[s1]}) %>%
        data.frame(NormFactor=., NormType=names(.))
}

getOffsetLineData <- function(s1, s2, n=1000) {
    x <- data.frame(A=aveLogCPM(dges$LoessNorm, dispersion=0.05, prior.count=0.5),
                    Offset=dges$LoessNorm$offset %>% {.[,s2] - .[,s1]} %>% divide_by(log(2)))
    f <- approxfun(x$A, x$Offset)
    data.frame(A=seq(from=min(x$A), to=max(x$A), length.out = n)) %>%
        mutate(M=f(A))
}

doMAPlot <- function(logcpm.matrix, s1, s2, linedata=getLineData(s1, s2), curvedata=NULL,
                     AveLogCPM, Acutoff=-2) {
    pointdata <- data.frame(S1=logcpm.matrix[,s1], S2=logcpm.matrix[,s2]) %>%
        transmute(A=(S1+S2)/2, M=S2-S1)
    if (!missing(AveLogCPM)) {
        pointdata$A <- AveLogCPM
    }
    pointdata %<>% filter(A >= Acutoff)
    ## Compute bandwidth and kernel smooth surface
    H <- pointdata %>% Hbcv.diag(binned=TRUE) %>% divide_by(4)
    k <- pointdata %>%
        as.matrix %>%
        kde(gridsize=1024, bgridsize=rep(1024, 2), verbose=TRUE,
            H=H, binned=TRUE)
    ## Sometimes the estimate goes a bit negative, which is no good

    densdata <- melt(k$estimate) %>%
        transmute(
            A=k$eval.points[[1]][Var1],
            M=k$eval.points[[2]][Var2],
            Density=value %>% pmax(0),
            ## Part of a hack to make the alpha look less bad
            AlphaDens=value %>% pmax(1e-15))

    p <- ggplot(pointdata) +
        coord_fixed(ratio=1/2) +
        ## MA Plot density
        geom_raster(aes(x=A, y=M, fill=Density, alpha=AlphaDens),
                    data=densdata,
                    interpolate=TRUE) +
        scale_fill_gradientn(colors=suppressWarnings(brewer.pal(Inf, "Blues")),
                             trans=power_trans(1/8),
                             name="Density") +
        scale_alpha_continuous(trans=power_trans(1/40), guide=FALSE)
    if (!is.null(linedata) && nrow(linedata) > 0) {
        p <- p +
            ## Normalization lines
            geom_hline(data=linedata, aes(yintercept=NormFactor, color=NormType)) +
            scale_color_discrete(name="Norm Type")
    }
    if (!is.null(curvedata)) {
        p <- p + geom_line(data=curvedata, aes(x=A, y=M))
    }
    p
}
```

With the preparatory code in place, we can now make the MA plots. First, we make basic MA plots, with log difference (M) on the y-axis and the log mean (A) on the x-axis. We also plot each normalization factor as a horizontal line, indicating where that normalization method would place the zero line.

```{r maplot_windows}
p <- seq_len(floor(length(bn.higher.samples) / 2)) %>%
    lapply(function(i) {
        s1 <- bn.higher.samples[i]
        s2 <- bn.higher.samples[length(bn.higher.samples) - i + 1]
        doMAPlot(logcpm, s1, s2) +
            labs(title=sprintf("MA plot of %s windows", params$window_size),
                 subtitle=sprintf("%s vs %s", colnames(dge)[s1], colnames(dge)[s2]))
    })
ggprint(p)
```

Now, we make the same plots, but for the x-axis, we use the average log2 CPM of the whole dataset, rather than the log mean of the two samples being plotted. The advantage of this is that it puts all the plots on a common x-axis, and it also allows us to add a curve representing the loess normalization, since this normalization is calculated relative to the same average log2 CPM scale. The disadvantage is that this smears the plots horizontally, since windows with similar counts in the two specific samples will have different counts in all the other samples, leading to a spreading of previously similar A values.

```{r maplot_windows_Acommon}
p <- seq_len(floor(length(bn.higher.samples) / 2)) %>%
    lapply(function(i) {
        s1 <- bn.higher.samples[i]
        s2 <- bn.higher.samples[length(bn.higher.samples) - i + 1]
        doMAPlot(logcpm, s1, s2, AveLogCPM=AveLogCPM,
                 curvedata=getOffsetLineData(s1, s2)) +
            labs(title=sprintf("MA plot of %s windows with common A scale", params$window_size),
                 subtitle=sprintf("%s vs %s", colnames(dge)[s1], colnames(dge)[s2]))
    })
ggprint(p)
```

Next, instead of plotting the loess normalization line, we make the MA plot using loess-normalized log2 CPM values. Effectively, this should center each entire plot vertically on M = 0, using the loess normalization as a guide.

```{r maplot_windows_loess_norm}
p <- seq_len(floor(length(bn.higher.samples) / 2)) %>%
    lapply(function(i) {
        s1 <- bn.higher.samples[i]
        s2 <- bn.higher.samples[length(bn.higher.samples) - i + 1]
        doMAPlot(logcpm.loess, s1, s2, linedata = NULL) +
            geom_hline(yintercept=0) + 
            labs(title=sprintf("MA plot of %s windows, loess normalized", params$window_size),
                 subtitle=sprintf("%s vs %s", colnames(dge)[s1], colnames(dge)[s2]))
    })
ggprint(p)
```

Last, we make MA plots for the 10kb bins that were used to compute the background normalization.

```{r maplot_bigbins}
p <- seq_len(floor(length(bn.higher.samples) / 2)) %>%
    lapply(function(i) {
        s1 <- bn.higher.samples[i]
        s2 <- bn.higher.samples[length(bn.higher.samples) - i + 1]
        doMAPlot(bigbin.logcpm, s1, s2) +
            labs(title=sprintf("MA plot of %s bins", params$bigbin_size),
                 subtitle=sprintf("%s vs %s", colnames(dge)[s1], colnames(dge)[s2]))
    })
print(p)
```

These plots seem to show that some samples have significant efficiency biases, visible as a trend in the MA plot. This further supports the choice of high-abundance peak-overlapping windows for normalization as well as our choice to regress out the effect of FRiP, which is a measure of ChIP pulldown efficiency.
